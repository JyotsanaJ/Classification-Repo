{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bagging (Bootstrap Aggregation) : Parallel training,  of multiple models then choosing output based on majority vote.\n",
    "\n",
    "* Boosting: Sequential training, Combines weak learners with strong learners. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Row sampling - taken from data with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "* Handles dimentionality\n",
    "* Diverse trees are generated\n",
    "* Stable\n",
    "* Handles overfitting well\n",
    "\n",
    "Disadvantage:\n",
    "* Slow due to multiple fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100) (100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "# 2 classes\n",
    "X, y = make_classification(n_features=100, n_classes=10, n_informative=80, n_clusters_per_class=2)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 100), (20, 100), (80,), (20,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=42) \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                            criterion=\"gini\",\n",
    "                            max_depth=None,\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            min_weight_fraction_leaf=0.0,\n",
    "                            max_features=\"sqrt\",\n",
    "                            max_leaf_nodes=None,\n",
    "                            min_impurity_decrease=0.0,\n",
    "                            bootstrap=True,\n",
    "                            oob_score=False,\n",
    "                            n_jobs=None,\n",
    "                            random_state=None,\n",
    "                            verbose=0,\n",
    "                            warm_start=False, # reuse the solution of the previous call to fit and add more estimators to the ensemble\n",
    "                            class_weight=None, \n",
    "                            ccp_alpha=0.0, # subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen\n",
    "                            max_samples=None,\n",
    "                            monotonic_cst=None\n",
    ")\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(y_test == prediction) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 4, 4, 2, 9, 1, 6, 6, 4, 9, 3, 6, 6, 3, 5, 9, 8, 2, 9])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                            criterion=\"gini\",\n",
    "                            max_depth=None,\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            min_weight_fraction_leaf=0.0,\n",
    "                            max_features=None,\n",
    "                            max_leaf_nodes=None,\n",
    "                            min_impurity_decrease=0.0,\n",
    "                            bootstrap=True,\n",
    "                            oob_score=True,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=None,\n",
    "                            verbose=0,\n",
    "                            warm_start=True, # reuse the solution of the previous call to fit and add more estimators to the ensemble\n",
    "                            class_weight=None, \n",
    "                            ccp_alpha=0.0, # subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen\n",
    "                            max_samples=None,\n",
    "                            monotonic_cst=None\n",
    ")\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0875"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(y_test == prediction) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05, 0.05, 0.07, 0.06, 0.09, 0.24, 0.11, 0.11, 0.1 , 0.12],\n",
       "       [0.01, 0.13, 0.14, 0.08, 0.16, 0.09, 0.11, 0.1 , 0.05, 0.13],\n",
       "       [0.13, 0.04, 0.06, 0.12, 0.11, 0.14, 0.16, 0.14, 0.03, 0.07],\n",
       "       [0.19, 0.1 , 0.08, 0.11, 0.12, 0.04, 0.06, 0.12, 0.07, 0.11],\n",
       "       [0.1 , 0.07, 0.25, 0.11, 0.06, 0.06, 0.04, 0.13, 0.05, 0.13],\n",
       "       [0.17, 0.04, 0.11, 0.02, 0.07, 0.04, 0.09, 0.13, 0.09, 0.24],\n",
       "       [0.11, 0.2 , 0.07, 0.14, 0.11, 0.04, 0.06, 0.09, 0.06, 0.12],\n",
       "       [0.06, 0.24, 0.07, 0.08, 0.14, 0.02, 0.07, 0.15, 0.11, 0.06],\n",
       "       [0.19, 0.05, 0.06, 0.02, 0.06, 0.08, 0.12, 0.16, 0.11, 0.15],\n",
       "       [0.04, 0.2 , 0.12, 0.11, 0.11, 0.11, 0.09, 0.04, 0.07, 0.11],\n",
       "       [0.02, 0.11, 0.09, 0.08, 0.08, 0.03, 0.1 , 0.06, 0.22, 0.21],\n",
       "       [0.09, 0.16, 0.05, 0.17, 0.09, 0.05, 0.1 , 0.1 , 0.06, 0.13],\n",
       "       [0.14, 0.11, 0.15, 0.11, 0.16, 0.03, 0.07, 0.06, 0.06, 0.11],\n",
       "       [0.12, 0.08, 0.14, 0.08, 0.08, 0.1 , 0.1 , 0.09, 0.07, 0.14],\n",
       "       [0.11, 0.1 , 0.09, 0.04, 0.1 , 0.02, 0.07, 0.15, 0.14, 0.18],\n",
       "       [0.18, 0.19, 0.16, 0.06, 0.05, 0.06, 0.08, 0.04, 0.  , 0.18],\n",
       "       [0.07, 0.11, 0.12, 0.09, 0.12, 0.02, 0.12, 0.08, 0.12, 0.15],\n",
       "       [0.04, 0.06, 0.12, 0.12, 0.1 , 0.11, 0.1 , 0.1 , 0.05, 0.2 ],\n",
       "       [0.2 , 0.09, 0.23, 0.08, 0.07, 0.  , 0.06, 0.09, 0.  , 0.18],\n",
       "       [0.11, 0.09, 0.11, 0.14, 0.08, 0.18, 0.06, 0.09, 0.08, 0.06]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01766151, 0.01019349, 0.00561448, 0.01118886, 0.00919792,\n",
       "       0.00811215, 0.00727606, 0.01007925, 0.01031755, 0.00925975,\n",
       "       0.02404884, 0.01003255, 0.01073527, 0.01385061, 0.00955418,\n",
       "       0.00473085, 0.01079059, 0.00847662, 0.00772717, 0.01703401,\n",
       "       0.0086725 , 0.00671646, 0.01025203, 0.00423674, 0.00372776,\n",
       "       0.00950022, 0.00397842, 0.0060015 , 0.01090547, 0.00982236,\n",
       "       0.00481766, 0.005236  , 0.01080384, 0.0102584 , 0.00793475,\n",
       "       0.01046419, 0.01281942, 0.01331624, 0.00617849, 0.01690533,\n",
       "       0.00608743, 0.00246115, 0.01285234, 0.00396996, 0.00810509,\n",
       "       0.00934045, 0.00894128, 0.0168459 , 0.00817011, 0.00505747,\n",
       "       0.009146  , 0.00709868, 0.00710193, 0.00514853, 0.01128595,\n",
       "       0.00360629, 0.0103941 , 0.0057376 , 0.00681693, 0.01042661,\n",
       "       0.00969956, 0.0026323 , 0.013757  , 0.01143736, 0.01537705,\n",
       "       0.00557788, 0.02076202, 0.01394456, 0.00280664, 0.00715216,\n",
       "       0.00674864, 0.01199737, 0.01129382, 0.01521966, 0.01563371,\n",
       "       0.00536406, 0.01040706, 0.00616733, 0.01710196, 0.01517979,\n",
       "       0.00885392, 0.01301441, 0.00769585, 0.00717924, 0.00220398,\n",
       "       0.00913314, 0.02416372, 0.0045301 , 0.00823584, 0.00834983,\n",
       "       0.01262652, 0.03019806, 0.03369001, 0.00734214, 0.00943294,\n",
       "       0.01799388, 0.00526854, 0.00591105, 0.00736556, 0.01152798])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRIDSEARCHCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "params = {\n",
    "    'max_depth': [2,3,5,10,20],\n",
    "    'min_samples_leaf': [5,10,20,50,100,200],\n",
    "    'n_estimators': [10,25,30,50,100,200]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                           param_grid=params,\n",
    "                           cv = 4,\n",
    "                           n_jobs=-1, \n",
    "                           verbose=1, \n",
    "                           scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n",
      "CPU times: user 174 ms, sys: 61.8 ms, total: 236 ms\n",
      "Wall time: 7.28 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 5, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [5, 10, 20, 50, 100, 200],\n",
       "                         &#x27;n_estimators&#x27;: [10, 25, 30, 50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 5, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [5, 10, 20, 50, 100, 200],\n",
       "                         &#x27;n_estimators&#x27;: [10, 25, 30, 50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 5, 10, 20],\n",
       "                         'min_samples_leaf': [5, 10, 20, 50, 100, 200],\n",
       "                         'n_estimators': [10, 25, 30, 50, 100, 200]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01702094, 0.03266937, 0.03886247, 0.04286295, 0.08093274,\n",
       "        0.12401521, 0.02110356, 0.02754778, 0.02562952, 0.03450722,\n",
       "        0.07455277, 0.12230343, 0.01961476, 0.0253908 , 0.0236305 ,\n",
       "        0.03924805, 0.06287068, 0.1238876 , 0.02227175, 0.02681899,\n",
       "        0.02447098, 0.03739524, 0.06617486, 0.1043433 , 0.01619238,\n",
       "        0.02169436, 0.03061157, 0.0464071 , 0.0805403 , 0.12765896,\n",
       "        0.01875424, 0.01977849, 0.02251929, 0.03509802, 0.06908727,\n",
       "        0.12324548, 0.02225077, 0.02475947, 0.02955276, 0.04494697,\n",
       "        0.07043004, 0.12245196, 0.02285987, 0.03996682, 0.03711873,\n",
       "        0.0423311 , 0.06970286, 0.12823528, 0.02681923, 0.02410668,\n",
       "        0.029194  , 0.0451082 , 0.07179248, 0.1427812 , 0.01537782,\n",
       "        0.02095574, 0.02673423, 0.03668284, 0.0674023 , 0.12138796,\n",
       "        0.01839542, 0.02549559, 0.03057265, 0.0422045 , 0.0617308 ,\n",
       "        0.14692825, 0.0212459 , 0.0248881 , 0.02534032, 0.04227972,\n",
       "        0.07649052, 0.10474795, 0.02016681, 0.03767395, 0.03045422,\n",
       "        0.04769146, 0.07424557, 0.14044571, 0.01797551, 0.03214139,\n",
       "        0.02610826, 0.03910148, 0.07587898, 0.16839033, 0.01821011,\n",
       "        0.02435255, 0.02305108, 0.04027724, 0.0898627 , 0.13532776,\n",
       "        0.01799673, 0.02722389, 0.03109801, 0.03637606, 0.075993  ,\n",
       "        0.15713644, 0.02031255, 0.02495819, 0.02497256, 0.03732556,\n",
       "        0.06635797, 0.11928046, 0.01800048, 0.01875371, 0.03483504,\n",
       "        0.04284126, 0.06039602, 0.10823953, 0.01781523, 0.02765399,\n",
       "        0.03319025, 0.04636526, 0.06755948, 0.12929738, 0.01728642,\n",
       "        0.02193952, 0.02977657, 0.03129947, 0.08093417, 0.16145706,\n",
       "        0.01801175, 0.0230726 , 0.026622  , 0.03770477, 0.06537873,\n",
       "        0.11780578, 0.01784903, 0.02005261, 0.02312797, 0.03551501,\n",
       "        0.06555825, 0.11664701, 0.01628208, 0.02472943, 0.02406329,\n",
       "        0.03547072, 0.07065678, 0.11503881, 0.01682562, 0.02263606,\n",
       "        0.03834569, 0.03329277, 0.06787926, 0.1156435 , 0.01738513,\n",
       "        0.02664602, 0.03214943, 0.04631561, 0.0840345 , 0.11303306,\n",
       "        0.01678556, 0.02438247, 0.02509284, 0.04049599, 0.0725891 ,\n",
       "        0.13400751, 0.01854473, 0.02045149, 0.02940506, 0.04438376,\n",
       "        0.07576162, 0.14747518, 0.01958698, 0.02076644, 0.0243665 ,\n",
       "        0.03694165, 0.06795472, 0.10728848, 0.02064347, 0.02679425,\n",
       "        0.02385116, 0.05526572, 0.06424528, 0.10740566, 0.01524401,\n",
       "        0.02598155, 0.02030498, 0.03157896, 0.05133009, 0.08853471]),\n",
       " 'std_fit_time': array([0.00141714, 0.00213247, 0.00443239, 0.00766102, 0.00647882,\n",
       "        0.00392375, 0.00134101, 0.00892232, 0.00668179, 0.00429234,\n",
       "        0.00410866, 0.00183189, 0.00187158, 0.00939026, 0.00671392,\n",
       "        0.00597614, 0.01067991, 0.02584713, 0.00371151, 0.00405345,\n",
       "        0.00676591, 0.01127764, 0.00251773, 0.01094908, 0.00178659,\n",
       "        0.00510743, 0.00583282, 0.01459725, 0.02611909, 0.02122448,\n",
       "        0.00208351, 0.00290258, 0.00679625, 0.00359644, 0.00634817,\n",
       "        0.00880632, 0.00440281, 0.00398892, 0.00385839, 0.00261098,\n",
       "        0.01098506, 0.020022  , 0.00327067, 0.00146362, 0.01454638,\n",
       "        0.00635891, 0.0193833 , 0.01984996, 0.0102299 , 0.00768317,\n",
       "        0.00580133, 0.01047521, 0.00969242, 0.03499784, 0.00153981,\n",
       "        0.00496581, 0.00533824, 0.00310372, 0.01133144, 0.02103158,\n",
       "        0.00519268, 0.00645665, 0.00181046, 0.00866659, 0.00515499,\n",
       "        0.03765087, 0.00490553, 0.00318616, 0.00498186, 0.00547231,\n",
       "        0.01688891, 0.01331531, 0.00546448, 0.019018  , 0.00896398,\n",
       "        0.0036254 , 0.01580804, 0.01430298, 0.00168566, 0.00749165,\n",
       "        0.0062913 , 0.00794778, 0.0245199 , 0.02478994, 0.00113224,\n",
       "        0.00520186, 0.00386127, 0.00773498, 0.02198893, 0.02504121,\n",
       "        0.0013774 , 0.0054914 , 0.00815542, 0.01176872, 0.02096589,\n",
       "        0.05276467, 0.00466572, 0.00139445, 0.00346723, 0.00209784,\n",
       "        0.00245062, 0.00807815, 0.00151933, 0.00280162, 0.01070138,\n",
       "        0.00648678, 0.0079429 , 0.00718206, 0.00201171, 0.00363002,\n",
       "        0.00055814, 0.00749911, 0.01331361, 0.00819594, 0.0011261 ,\n",
       "        0.00395629, 0.00196796, 0.00263262, 0.01911742, 0.04778117,\n",
       "        0.00291834, 0.00503863, 0.0043726 , 0.00600208, 0.00364673,\n",
       "        0.01656141, 0.00088336, 0.00582529, 0.0066479 , 0.00223327,\n",
       "        0.00599521, 0.02246102, 0.00047354, 0.00682745, 0.00650025,\n",
       "        0.00283072, 0.00905268, 0.02605295, 0.00232905, 0.0072073 ,\n",
       "        0.01435646, 0.00440945, 0.00605894, 0.01709634, 0.00298109,\n",
       "        0.00586463, 0.00532851, 0.00192068, 0.02329075, 0.01068131,\n",
       "        0.00255373, 0.00519998, 0.00576588, 0.00497827, 0.0149619 ,\n",
       "        0.00798087, 0.00269961, 0.00430945, 0.00995351, 0.01024625,\n",
       "        0.01760661, 0.05637928, 0.00478123, 0.00643779, 0.00595536,\n",
       "        0.0060527 , 0.01572679, 0.00931735, 0.00453495, 0.00611891,\n",
       "        0.00555684, 0.02081426, 0.0056715 , 0.02828092, 0.00113501,\n",
       "        0.00782878, 0.00498353, 0.0035372 , 0.00662496, 0.00469922]),\n",
       " 'mean_score_time': array([0.01440763, 0.01704377, 0.01498878, 0.01713854, 0.0239045 ,\n",
       "        0.01625478, 0.02337092, 0.01497149, 0.01590228, 0.01610255,\n",
       "        0.01695496, 0.01423061, 0.01712054, 0.01665926, 0.01579452,\n",
       "        0.01921022, 0.02085686, 0.01570386, 0.02003074, 0.01699293,\n",
       "        0.0147385 , 0.01614106, 0.01774448, 0.02061474, 0.01385814,\n",
       "        0.01525164, 0.01688993, 0.01695424, 0.01517928, 0.02492291,\n",
       "        0.01548845, 0.01710689, 0.01542443, 0.01537901, 0.01867431,\n",
       "        0.02228272, 0.01867425, 0.0158596 , 0.01789147, 0.01819026,\n",
       "        0.02235472, 0.0183683 , 0.02070338, 0.01927942, 0.02390397,\n",
       "        0.01759148, 0.01867813, 0.0162394 , 0.01768863, 0.01490492,\n",
       "        0.02072155, 0.01656479, 0.024517  , 0.02621776, 0.01476687,\n",
       "        0.01524472, 0.01621228, 0.01704341, 0.01997191, 0.01722896,\n",
       "        0.01904231, 0.01491696, 0.01701301, 0.01733053, 0.01615745,\n",
       "        0.02202457, 0.02412713, 0.02142131, 0.02076018, 0.0223816 ,\n",
       "        0.02402425, 0.02181798, 0.01667827, 0.02178454, 0.02610576,\n",
       "        0.01790375, 0.01830673, 0.02555293, 0.01673293, 0.01750803,\n",
       "        0.01602572, 0.01673794, 0.01921356, 0.0170728 , 0.02046001,\n",
       "        0.01775968, 0.01569861, 0.01984972, 0.01529729, 0.02295631,\n",
       "        0.01921052, 0.01714087, 0.01635444, 0.02269298, 0.03357995,\n",
       "        0.01789588, 0.01592451, 0.01833808, 0.01580209, 0.01672447,\n",
       "        0.02670372, 0.01927733, 0.01645857, 0.02252603, 0.01908076,\n",
       "        0.01403314, 0.01485723, 0.01553231, 0.01665306, 0.01478434,\n",
       "        0.01605225, 0.01630825, 0.01798916, 0.01620156, 0.01796532,\n",
       "        0.0164575 , 0.01461238, 0.01576954, 0.01868826, 0.01894063,\n",
       "        0.01815969, 0.02045298, 0.01787919, 0.01729983, 0.01428503,\n",
       "        0.01570934, 0.01495779, 0.01471829, 0.01484424, 0.01462942,\n",
       "        0.02327389, 0.01754743, 0.0162667 , 0.01887149, 0.01533747,\n",
       "        0.01456994, 0.01669508, 0.01542741, 0.01611334, 0.03300709,\n",
       "        0.01485568, 0.0155865 , 0.0202055 , 0.01572227, 0.01460612,\n",
       "        0.01450926, 0.01884574, 0.01898164, 0.01717454, 0.01464492,\n",
       "        0.02016068, 0.01547599, 0.01402569, 0.01515204, 0.017717  ,\n",
       "        0.03378361, 0.01630265, 0.01690525, 0.0231207 , 0.01514053,\n",
       "        0.01666528, 0.01448399, 0.01604629, 0.01459944, 0.01973969,\n",
       "        0.01530272, 0.01525658, 0.01499659, 0.0280205 , 0.01756835,\n",
       "        0.01715577, 0.01598126, 0.01530176, 0.01559782, 0.01576251,\n",
       "        0.01500422, 0.01436728, 0.0149157 , 0.01374519, 0.01429874]),\n",
       " 'std_score_time': array([8.97658156e-04, 2.72475721e-03, 1.18940819e-03, 3.25607792e-03,\n",
       "        5.72378283e-03, 2.30567007e-03, 1.04636591e-02, 6.96613251e-04,\n",
       "        5.34765299e-04, 9.60329187e-04, 1.88417880e-03, 1.21893728e-03,\n",
       "        2.10422005e-03, 2.10884257e-03, 2.53795817e-03, 4.25848241e-03,\n",
       "        6.56603539e-03, 1.60923866e-03, 5.36261346e-03, 1.91582300e-03,\n",
       "        1.41490540e-03, 3.34452754e-03, 1.88702878e-03, 5.86917724e-03,\n",
       "        9.61285696e-04, 1.39519624e-03, 3.22670798e-03, 2.07796058e-03,\n",
       "        1.00192756e-03, 1.27727742e-02, 1.57412861e-03, 1.96484643e-03,\n",
       "        1.79186985e-03, 4.15700087e-04, 3.56013511e-03, 4.10005361e-03,\n",
       "        7.63561022e-03, 1.49348998e-03, 2.39698496e-03, 2.00460985e-03,\n",
       "        7.16595440e-03, 3.14876005e-03, 6.35451400e-03, 2.81140373e-03,\n",
       "        4.83233338e-03, 5.05108643e-03, 5.15943329e-03, 2.84452173e-03,\n",
       "        4.20180804e-03, 2.68976952e-03, 6.04621059e-03, 2.09292118e-03,\n",
       "        1.26326128e-02, 6.61490113e-03, 8.20043543e-04, 1.94206071e-03,\n",
       "        7.39276318e-04, 1.93939362e-03, 6.57093343e-03, 3.23646865e-03,\n",
       "        2.08539760e-03, 1.97541268e-03, 2.36504883e-03, 4.58363147e-03,\n",
       "        3.45826445e-03, 2.44024826e-03, 5.08675799e-03, 3.67871425e-03,\n",
       "        3.61090901e-03, 5.04711327e-03, 1.46421508e-02, 2.80384517e-03,\n",
       "        1.84396696e-03, 7.79814563e-03, 1.80897247e-02, 4.81968597e-03,\n",
       "        4.59791889e-03, 9.08836736e-03, 3.65372197e-03, 3.05395679e-03,\n",
       "        3.25756094e-03, 2.26108794e-03, 5.63157641e-03, 2.20732112e-03,\n",
       "        4.70866079e-03, 5.00986110e-03, 3.92422401e-04, 3.99340591e-03,\n",
       "        9.52922473e-04, 7.82481880e-03, 5.90900796e-03, 3.03799799e-03,\n",
       "        2.19804569e-03, 8.47615700e-03, 1.98653390e-02, 2.93637370e-03,\n",
       "        9.47764074e-04, 3.64074014e-03, 1.19751069e-03, 2.68728503e-03,\n",
       "        1.19862784e-02, 4.39885486e-03, 1.94777080e-03, 9.72666451e-03,\n",
       "        3.80814782e-03, 4.10180834e-04, 3.67778621e-04, 1.87571198e-03,\n",
       "        1.61410379e-03, 1.39085854e-03, 7.97174312e-04, 3.47601413e-03,\n",
       "        3.80605183e-03, 2.77190951e-03, 4.33325831e-03, 3.74695875e-03,\n",
       "        1.67670694e-03, 2.25290656e-03, 4.19974237e-03, 4.06426181e-03,\n",
       "        3.79396873e-03, 2.56007060e-03, 1.36548512e-03, 2.00453342e-03,\n",
       "        9.71397322e-04, 2.43611283e-03, 1.07914997e-03, 7.01931123e-04,\n",
       "        7.69463495e-04, 1.49572390e-03, 7.81491256e-03, 4.93500172e-03,\n",
       "        8.18072905e-04, 5.17652446e-03, 1.35874277e-03, 1.88675817e-03,\n",
       "        2.33668467e-03, 6.47413733e-05, 1.58904689e-03, 1.23003821e-02,\n",
       "        1.92272385e-03, 1.01271090e-03, 6.96501432e-03, 1.31692678e-03,\n",
       "        1.35606219e-03, 1.73909236e-03, 5.42922401e-03, 4.32749279e-03,\n",
       "        5.68584952e-03, 5.59074319e-04, 5.46157638e-03, 7.14677080e-04,\n",
       "        9.54124627e-04, 1.91268885e-03, 3.10601072e-03, 1.74542692e-02,\n",
       "        1.81736879e-03, 2.07620702e-03, 1.16837037e-02, 1.06211689e-03,\n",
       "        3.09048388e-03, 2.65262344e-03, 2.36843009e-03, 8.66455637e-04,\n",
       "        6.91875134e-03, 4.83336512e-04, 2.67962024e-03, 1.40931182e-03,\n",
       "        1.70756375e-02, 3.61039637e-03, 8.33900695e-04, 2.61850407e-03,\n",
       "        4.27797194e-04, 5.22227447e-03, 7.89351157e-04, 4.15244248e-04,\n",
       "        8.13589443e-04, 1.80464825e-03, 5.84706254e-04, 8.44842255e-04]),\n",
       " 'param_max_depth': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    100, 100, 200, 200, 200, 200, 200, 200, 5, 5, 5, 5, 5,\n",
       "                    5, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 50,\n",
       "                    50, 50, 50, 50, 50, 100, 100, 100, 100, 100, 100, 200,\n",
       "                    200, 200, 200, 200, 200, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
       "                    10, 10, 10, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50,\n",
       "                    50, 100, 100, 100, 100, 100, 100, 200, 200, 200, 200,\n",
       "                    200, 200, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 20,\n",
       "                    20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 100, 100,\n",
       "                    100, 100, 100, 100, 200, 200, 200, 200, 200, 200, 5, 5,\n",
       "                    5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
       "                    100, 200, 200, 200, 200, 200, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 25, 30, 50, 100, 200, 10, 25, 30, 50, 100, 200, 10,\n",
       "                    25, 30, 50, 100, 200, 10, 25, 30, 50, 100, 200, 10, 25,\n",
       "                    30, 50, 100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30,\n",
       "                    50, 100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200, 10, 25, 30, 50,\n",
       "                    100, 200, 10, 25, 30, 50, 100, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 2, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 5, 'n_estimators': 25},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 5, 'n_estimators': 30},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 5, 'n_estimators': 200},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 10, 'n_estimators': 25},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 10, 'n_estimators': 30},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 10, 'n_estimators': 200},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 20, 'n_estimators': 10},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 20, 'n_estimators': 25},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 20, 'n_estimators': 30},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 50, 'n_estimators': 25},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 50, 'n_estimators': 30},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 50, 'n_estimators': 200},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 100, 'n_estimators': 10},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 100, 'n_estimators': 25},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 100, 'n_estimators': 30},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 100, 'n_estimators': 50},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 100, 'n_estimators': 100},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 100, 'n_estimators': 200},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 200, 'n_estimators': 10},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 200, 'n_estimators': 25},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 200, 'n_estimators': 30},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 200, 'n_estimators': 50},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 200, 'n_estimators': 100},\n",
       "  {'max_depth': 2, 'min_samples_leaf': 200, 'n_estimators': 200},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'n_estimators': 25},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'n_estimators': 30},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'n_estimators': 200},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 10, 'n_estimators': 25},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 10, 'n_estimators': 30},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 10, 'n_estimators': 200},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 20, 'n_estimators': 10},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 20, 'n_estimators': 25},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 20, 'n_estimators': 30},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 50, 'n_estimators': 25},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 50, 'n_estimators': 30},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 50, 'n_estimators': 200},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 100, 'n_estimators': 10},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 100, 'n_estimators': 25},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 100, 'n_estimators': 30},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 100, 'n_estimators': 50},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 100, 'n_estimators': 100},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 100, 'n_estimators': 200},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 200, 'n_estimators': 10},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 200, 'n_estimators': 25},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 200, 'n_estimators': 30},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 200, 'n_estimators': 50},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 200, 'n_estimators': 100},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 200, 'n_estimators': 200},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 25},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 30},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 200},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 10, 'n_estimators': 25},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 10, 'n_estimators': 30},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 10, 'n_estimators': 200},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 20, 'n_estimators': 10},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 20, 'n_estimators': 25},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 20, 'n_estimators': 30},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 50, 'n_estimators': 25},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 50, 'n_estimators': 30},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 50, 'n_estimators': 200},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 100, 'n_estimators': 10},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 100, 'n_estimators': 25},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 100, 'n_estimators': 30},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 100, 'n_estimators': 50},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 100, 'n_estimators': 100},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 100, 'n_estimators': 200},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 200, 'n_estimators': 10},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 200, 'n_estimators': 25},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 200, 'n_estimators': 30},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 200, 'n_estimators': 50},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 200, 'n_estimators': 100},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 200, 'n_estimators': 200},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 25},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 30},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 200},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 10, 'n_estimators': 25},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 10, 'n_estimators': 30},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 10, 'n_estimators': 200},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 20, 'n_estimators': 10},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 20, 'n_estimators': 25},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 20, 'n_estimators': 30},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 50, 'n_estimators': 25},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 50, 'n_estimators': 30},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 50, 'n_estimators': 200},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 100, 'n_estimators': 10},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 100, 'n_estimators': 25},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 100, 'n_estimators': 30},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 100, 'n_estimators': 50},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 100, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 100, 'n_estimators': 200},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 200, 'n_estimators': 10},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 200, 'n_estimators': 25},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 200, 'n_estimators': 30},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 200, 'n_estimators': 50},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 200, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 200, 'n_estimators': 200},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 25},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 30},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 200},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 10, 'n_estimators': 25},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 10, 'n_estimators': 30},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 10, 'n_estimators': 200},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 20, 'n_estimators': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 20, 'n_estimators': 25},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 20, 'n_estimators': 30},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 20, 'n_estimators': 50},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 20, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 20, 'n_estimators': 200},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 50, 'n_estimators': 25},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 50, 'n_estimators': 30},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 50, 'n_estimators': 200},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 100, 'n_estimators': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 100, 'n_estimators': 25},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 100, 'n_estimators': 30},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 100, 'n_estimators': 50},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 100, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 100, 'n_estimators': 200},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 200, 'n_estimators': 10},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 200, 'n_estimators': 25},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 200, 'n_estimators': 30},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 200, 'n_estimators': 50},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 200, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 200, 'n_estimators': 200}],\n",
       " 'split0_test_score': array([0.05, 0.1 , 0.15, 0.05, 0.1 , 0.05, 0.2 , 0.  , 0.  , 0.05, 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.15, 0.  , 0.05, 0.05, 0.05, 0.1 , 0.1 , 0.2 , 0.  ,\n",
       "        0.  , 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.05, 0.05, 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.05, 0.  , 0.05, 0.1 , 0.15,\n",
       "        0.15, 0.2 , 0.  , 0.  , 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.05, 0.05,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.05, 0.  ,\n",
       "        0.05, 0.1 , 0.15, 0.15, 0.2 , 0.  , 0.  , 0.05, 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.15, 0.05, 0.  , 0.05, 0.1 , 0.15, 0.15, 0.2 , 0.  , 0.  , 0.05,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.05, 0.05, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.15]),\n",
       " 'split1_test_score': array([0.15, 0.2 , 0.15, 0.15, 0.  , 0.05, 0.05, 0.2 , 0.15, 0.1 , 0.  ,\n",
       "        0.  , 0.1 , 0.1 , 0.2 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.2 , 0.2 , 0.05, 0.  , 0.05, 0.2 ,\n",
       "        0.15, 0.1 , 0.  , 0.  , 0.1 , 0.1 , 0.2 , 0.15, 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.15, 0.  ,\n",
       "        0.  , 0.05, 0.2 , 0.15, 0.1 , 0.  , 0.  , 0.1 , 0.1 , 0.2 , 0.15,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.15, 0.15, 0.  , 0.  , 0.05, 0.2 , 0.15, 0.1 , 0.  , 0.  , 0.1 ,\n",
       "        0.1 , 0.2 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.15, 0.15, 0.  , 0.  , 0.05, 0.2 , 0.15, 0.1 ,\n",
       "        0.  , 0.  , 0.1 , 0.1 , 0.2 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 ]),\n",
       " 'split2_test_score': array([0.1 , 0.1 , 0.1 , 0.2 , 0.15, 0.15, 0.15, 0.1 , 0.15, 0.1 , 0.1 ,\n",
       "        0.15, 0.2 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.15, 0.2 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.05, 0.1 , 0.1 , 0.1 ,\n",
       "        0.15, 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.2 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.05,\n",
       "        0.1 , 0.1 , 0.15, 0.15, 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.15, 0.2 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.05, 0.1 , 0.1 , 0.15, 0.15, 0.15, 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.15, 0.2 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 ]),\n",
       " 'split3_test_score': array([0.1 , 0.05, 0.1 , 0.15, 0.1 , 0.1 , 0.  , 0.15, 0.05, 0.15, 0.1 ,\n",
       "        0.1 , 0.2 , 0.1 , 0.15, 0.2 , 0.1 , 0.15, 0.15, 0.1 , 0.15, 0.15,\n",
       "        0.15, 0.15, 0.15, 0.1 , 0.15, 0.15, 0.15, 0.15, 0.15, 0.1 , 0.15,\n",
       "        0.15, 0.15, 0.15, 0.2 , 0.15, 0.15, 0.2 , 0.05, 0.1 , 0.1 , 0.15,\n",
       "        0.1 , 0.1 , 0.1 , 0.1 , 0.2 , 0.1 , 0.15, 0.2 , 0.1 , 0.15, 0.15,\n",
       "        0.1 , 0.15, 0.15, 0.15, 0.15, 0.15, 0.1 , 0.15, 0.15, 0.15, 0.15,\n",
       "        0.15, 0.1 , 0.15, 0.15, 0.15, 0.15, 0.2 , 0.15, 0.2 , 0.2 , 0.05,\n",
       "        0.15, 0.1 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.2 , 0.1 , 0.15, 0.2 ,\n",
       "        0.1 , 0.15, 0.15, 0.1 , 0.15, 0.15, 0.15, 0.15, 0.15, 0.1 , 0.15,\n",
       "        0.15, 0.15, 0.15, 0.15, 0.1 , 0.15, 0.15, 0.15, 0.15, 0.2 , 0.15,\n",
       "        0.2 , 0.2 , 0.05, 0.15, 0.1 , 0.15, 0.1 , 0.1 , 0.1 , 0.1 , 0.2 ,\n",
       "        0.1 , 0.15, 0.2 , 0.1 , 0.15, 0.15, 0.1 , 0.15, 0.15, 0.15, 0.15,\n",
       "        0.15, 0.1 , 0.15, 0.15, 0.15, 0.15, 0.15, 0.1 , 0.15, 0.15, 0.15,\n",
       "        0.15, 0.2 , 0.15, 0.2 , 0.2 , 0.05, 0.15, 0.1 , 0.15, 0.1 , 0.1 ,\n",
       "        0.1 , 0.1 , 0.2 , 0.1 , 0.15, 0.2 , 0.1 , 0.15, 0.15, 0.1 , 0.15,\n",
       "        0.15, 0.15, 0.15, 0.15, 0.1 , 0.15, 0.15, 0.15, 0.15, 0.15, 0.1 ,\n",
       "        0.15, 0.15, 0.15, 0.15]),\n",
       " 'mean_test_score': array([0.1   , 0.1125, 0.125 , 0.1375, 0.0875, 0.0875, 0.1   , 0.1125,\n",
       "        0.0875, 0.1   , 0.075 , 0.0875, 0.15  , 0.1   , 0.125 , 0.125 ,\n",
       "        0.1   , 0.1125, 0.1125, 0.1   , 0.1125, 0.1125, 0.1125, 0.125 ,\n",
       "        0.1125, 0.1   , 0.1125, 0.1125, 0.1125, 0.125 , 0.1125, 0.1   ,\n",
       "        0.1125, 0.1125, 0.1125, 0.125 , 0.1   , 0.1125, 0.125 , 0.1375,\n",
       "        0.075 , 0.075 , 0.125 , 0.1125, 0.0875, 0.0875, 0.075 , 0.0875,\n",
       "        0.15  , 0.1   , 0.125 , 0.125 , 0.1   , 0.1125, 0.1125, 0.1   ,\n",
       "        0.1125, 0.1125, 0.1125, 0.125 , 0.1125, 0.1   , 0.1125, 0.1125,\n",
       "        0.1125, 0.125 , 0.1125, 0.1   , 0.1125, 0.1125, 0.1125, 0.125 ,\n",
       "        0.1125, 0.075 , 0.125 , 0.1375, 0.075 , 0.1125, 0.125 , 0.1125,\n",
       "        0.0875, 0.0875, 0.075 , 0.0875, 0.15  , 0.1   , 0.125 , 0.125 ,\n",
       "        0.1   , 0.1125, 0.1125, 0.1   , 0.1125, 0.1125, 0.1125, 0.125 ,\n",
       "        0.1125, 0.1   , 0.1125, 0.1125, 0.1125, 0.125 , 0.1125, 0.1   ,\n",
       "        0.1125, 0.1125, 0.1125, 0.125 , 0.1125, 0.075 , 0.125 , 0.1375,\n",
       "        0.0875, 0.1125, 0.125 , 0.1125, 0.0875, 0.0875, 0.075 , 0.0875,\n",
       "        0.15  , 0.1   , 0.125 , 0.125 , 0.1   , 0.1125, 0.1125, 0.1   ,\n",
       "        0.1125, 0.1125, 0.1125, 0.125 , 0.1125, 0.1   , 0.1125, 0.1125,\n",
       "        0.1125, 0.125 , 0.1125, 0.1   , 0.1125, 0.1125, 0.1125, 0.125 ,\n",
       "        0.1125, 0.075 , 0.125 , 0.1375, 0.0875, 0.1125, 0.125 , 0.1125,\n",
       "        0.0875, 0.0875, 0.075 , 0.0875, 0.15  , 0.1   , 0.125 , 0.125 ,\n",
       "        0.1   , 0.1125, 0.1125, 0.1   , 0.1125, 0.1125, 0.1125, 0.125 ,\n",
       "        0.1125, 0.1   , 0.1125, 0.1125, 0.1125, 0.125 , 0.1125, 0.1   ,\n",
       "        0.1125, 0.1125, 0.1125, 0.125 ]),\n",
       " 'std_test_score': array([0.03535534, 0.05448624, 0.025     , 0.05448624, 0.05448624,\n",
       "        0.04145781, 0.07905694, 0.073951  , 0.06495191, 0.03535534,\n",
       "        0.04330127, 0.05448624, 0.05      , 0.        , 0.0559017 ,\n",
       "        0.0559017 , 0.        , 0.02165064, 0.02165064, 0.        ,\n",
       "        0.02165064, 0.02165064, 0.02165064, 0.025     , 0.02165064,\n",
       "        0.        , 0.02165064, 0.02165064, 0.02165064, 0.025     ,\n",
       "        0.02165064, 0.        , 0.02165064, 0.02165064, 0.02165064,\n",
       "        0.025     , 0.07071068, 0.04145781, 0.0559017 , 0.06495191,\n",
       "        0.025     , 0.04330127, 0.0559017 , 0.073951  , 0.05448624,\n",
       "        0.02165064, 0.04330127, 0.05448624, 0.05      , 0.        ,\n",
       "        0.0559017 , 0.0559017 , 0.        , 0.02165064, 0.02165064,\n",
       "        0.        , 0.02165064, 0.02165064, 0.02165064, 0.025     ,\n",
       "        0.02165064, 0.        , 0.02165064, 0.02165064, 0.02165064,\n",
       "        0.025     , 0.02165064, 0.        , 0.02165064, 0.02165064,\n",
       "        0.02165064, 0.025     , 0.05448624, 0.0559017 , 0.0559017 ,\n",
       "        0.04145781, 0.0559017 , 0.06495191, 0.0559017 , 0.073951  ,\n",
       "        0.05448624, 0.02165064, 0.04330127, 0.05448624, 0.05      ,\n",
       "        0.        , 0.0559017 , 0.0559017 , 0.        , 0.02165064,\n",
       "        0.02165064, 0.        , 0.02165064, 0.02165064, 0.02165064,\n",
       "        0.025     , 0.02165064, 0.        , 0.02165064, 0.02165064,\n",
       "        0.02165064, 0.025     , 0.02165064, 0.        , 0.02165064,\n",
       "        0.02165064, 0.02165064, 0.025     , 0.05448624, 0.0559017 ,\n",
       "        0.0559017 , 0.04145781, 0.06495191, 0.06495191, 0.0559017 ,\n",
       "        0.073951  , 0.05448624, 0.02165064, 0.04330127, 0.05448624,\n",
       "        0.05      , 0.        , 0.0559017 , 0.0559017 , 0.        ,\n",
       "        0.02165064, 0.02165064, 0.        , 0.02165064, 0.02165064,\n",
       "        0.02165064, 0.025     , 0.02165064, 0.        , 0.02165064,\n",
       "        0.02165064, 0.02165064, 0.025     , 0.02165064, 0.        ,\n",
       "        0.02165064, 0.02165064, 0.02165064, 0.025     , 0.05448624,\n",
       "        0.0559017 , 0.0559017 , 0.04145781, 0.06495191, 0.06495191,\n",
       "        0.0559017 , 0.073951  , 0.05448624, 0.02165064, 0.04330127,\n",
       "        0.05448624, 0.05      , 0.        , 0.0559017 , 0.0559017 ,\n",
       "        0.        , 0.02165064, 0.02165064, 0.        , 0.02165064,\n",
       "        0.02165064, 0.02165064, 0.025     , 0.02165064, 0.        ,\n",
       "        0.02165064, 0.02165064, 0.02165064, 0.025     , 0.02165064,\n",
       "        0.        , 0.02165064, 0.02165064, 0.02165064, 0.025     ]),\n",
       " 'rank_test_score': array([123, 116,  11,   6, 152, 152, 123,  45, 152, 123, 170, 152,   1,\n",
       "        123,  11,  11, 123,  45,  45, 123,  45,  45,  45,  11,  45, 123,\n",
       "         45,  45,  45,  11,  45, 123,  45,  45,  45,  11, 123,  45,  11,\n",
       "          6, 179, 170,  11,  45, 152, 152, 170, 152,   1, 123,  11,  11,\n",
       "        123,  45,  45, 123,  45,  45,  45,  11,  45, 123,  45,  45,  45,\n",
       "         11,  45, 123,  45,  45,  45,  11, 116, 170,  11,   6, 179, 120,\n",
       "         11,  45, 152, 152, 170, 152,   1, 123,  11,  11, 123,  45,  45,\n",
       "        123,  45,  45,  45,  11,  45, 123,  45,  45,  45,  11,  45, 123,\n",
       "         45,  45,  45,  11, 116, 170,  11,   6, 152, 120,  11,  45, 152,\n",
       "        152, 170, 152,   1, 123,  11,  11, 123,  45,  45, 123,  45,  45,\n",
       "         45,  11,  45, 123,  45,  45,  45,  11,  45, 123,  45,  45,  45,\n",
       "         11, 116, 170,  11,   6, 152, 120,  11,  45, 152, 152, 170, 152,\n",
       "          1, 123,  11,  11, 123,  45,  45, 123,  45,  45,  45,  11,  45,\n",
       "        123,  45,  45,  45,  11,  45, 123,  45,  45,  45,  11], dtype=int32)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=2, min_samples_leaf=20, n_estimators=10,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "{'max_depth': 2, 'min_samples_leaf': 20, 'n_estimators': 10}\n",
      "0.15000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using real life sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4), (120,), (30,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=42) \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10,\n",
    "                            criterion=\"gini\",\n",
    "                            n_jobs=-1,\n",
    "                            verbose=1,\n",
    "                            warm_start=False, # reuse the solution of the previous call to fit and add more estimators to the ensemble\n",
    ")\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum( y_test == prediction) /len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
